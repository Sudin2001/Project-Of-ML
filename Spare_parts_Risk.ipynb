{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yQbkdRoSiOCjYrjlfhw1M18DXgYlMh_5",
      "authorship_tag": "ABX9TyPao2xsBbAwufG0RNPxz7Rs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudin2001/Project-Of-ML/blob/main/Spare_parts_Risk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Import Required Libraries and Load Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "print(\"📊 EXCAVATOR SUPPLIER RISK ANALYSIS PROJECT\")\n",
        "print(\"=\" * 50)\n",
        "print(\"\\n🔄 Step 1: Loading Data Files...\")\n",
        "\n",
        "# Load all the datasets\n",
        "try:\n",
        "    parts_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/excavator_spare_parts_master.csv')\n",
        "    suppliers_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/suppliers_master.csv')\n",
        "    supplier_parts_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/supplier_parts_mapping.csv')\n",
        "    po_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/purchase_orders.csv')\n",
        "    production_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/production_schedule.csv')\n",
        "    parts_req_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/parts_requirements.csv')\n",
        "    inventory_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/inventory_status.csv')\n",
        "    risk_events_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/risk_events.csv')\n",
        "    supplier_risk_df = pd.read_csv('/content/drive/MyDrive/Risk model on spare parts supply chain disruption/supplier_risk_analysis.csv')\n",
        "\n",
        "    print(\"✅ All datasets loaded successfully!\")\n",
        "    print(f\"   • Parts Master: {len(parts_df)} records\")\n",
        "    print(f\"   • Suppliers: {len(suppliers_df)} records\")\n",
        "    print(f\"   • Purchase Orders: {len(po_df)} records\")\n",
        "    print(f\"   • Risk Events: {len(risk_events_df)} records\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading data: {e}\")\n",
        "    print(\"Please ensure all CSV files are in the current directory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxsTEJpJ9Y_u",
        "outputId": "dda2ddaa-ebb5-4fb3-d444-d55d7f22420f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 EXCAVATOR SUPPLIER RISK ANALYSIS PROJECT\n",
            "==================================================\n",
            "\n",
            "🔄 Step 1: Loading Data Files...\n",
            "✅ All datasets loaded successfully!\n",
            "   • Parts Master: 32 records\n",
            "   • Suppliers: 15 records\n",
            "   • Purchase Orders: 1654 records\n",
            "   • Risk Events: 945 records\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Feature Engineering for Risk Analysis\n",
        "print(\"\\n🔧 Step 3: Feature Engineering for Risk Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\n📈 Why Feature Engineering?\")\n",
        "print(\"Feature engineering transforms raw data into meaningful predictors for risk models.\")\n",
        "print(\"For supplier risk analysis, we need features that capture:\")\n",
        "print(\"- Historical performance patterns\")\n",
        "print(\"- Supplier characteristics and reliability\")\n",
        "print(\"- Order complexity and urgency\")\n",
        "print(\"- Seasonal and temporal patterns\")\n",
        "\n",
        "# Convert date columns to datetime\n",
        "po_df['PO_Date'] = pd.to_datetime(po_df['PO_Date'])\n",
        "po_df['Promised_Delivery_Date'] = pd.to_datetime(po_df['Promised_Delivery_Date'])\n",
        "po_df['Actual_Delivery_Date'] = pd.to_datetime(po_df['Actual_Delivery_Date'])\n",
        "\n",
        "# Create enhanced dataset by merging with master data\n",
        "print(\"\\n🔗 Creating Enhanced Dataset...\")\n",
        "\n",
        "# Merge with parts and suppliers data\n",
        "enhanced_df = po_df.merge(parts_df[['Part_ID', 'Category', 'Criticality']], on='Part_ID')\n",
        "enhanced_df = enhanced_df.merge(suppliers_df[['Supplier_ID', 'Supplier_Type', 'Years_Partnership',\n",
        "                                            'Financial_Rating', 'Historical_OTD_Pct', 'Location']], on='Supplier_ID')\n",
        "\n",
        "print(f\"✅ Enhanced dataset created with {enhanced_df.shape[1]} features\")\n",
        "\n",
        "# Feature Engineering: Historical Performance Features\n",
        "print(\"\\n📊 Creating Historical Performance Features...\")\n",
        "\n",
        "# 1. Supplier Rolling Performance (Last 30 days, 60 days, 90 days)\n",
        "def calculate_rolling_metrics(df, supplier_id, reference_date, window_days):\n",
        "    \"\"\"Calculate supplier performance over a rolling window\"\"\"\n",
        "    cutoff_date = reference_date - pd.Timedelta(days=window_days)\n",
        "    historical_pos = df[(df['Supplier_ID'] == supplier_id) &\n",
        "                       (df['PO_Date'] >= cutoff_date) &\n",
        "                       (df['PO_Date'] < reference_date)]\n",
        "\n",
        "    if len(historical_pos) == 0:\n",
        "        return {\n",
        "            'orders_count': 0,\n",
        "            'otd_rate': 0.5,  # Default neutral value\n",
        "            'avg_delay': 0,\n",
        "            'delay_variance': 0,\n",
        "            'total_value': 0\n",
        "        }\n",
        "\n",
        "    return {\n",
        "        'orders_count': len(historical_pos),\n",
        "        'otd_rate': historical_pos['Is_On_Time'].mean(),\n",
        "        'avg_delay': historical_pos[historical_pos['Is_Late']]['Delay_Days'].mean() if sum(historical_pos['Is_Late']) > 0 else 0,\n",
        "        'delay_variance': historical_pos['Delay_Days'].var(),\n",
        "        'total_value': historical_pos['Order_Value_INR'].sum()\n",
        "    }\n",
        "\n",
        "# Calculate rolling metrics for each PO (this simulates real-time risk scoring)\n",
        "rolling_features = []\n",
        "\n",
        "for idx, row in enhanced_df.iterrows():\n",
        "    # Calculate 30-day and 90-day rolling metrics\n",
        "    metrics_30 = calculate_rolling_metrics(enhanced_df, row['Supplier_ID'], row['PO_Date'], 30)\n",
        "    metrics_90 = calculate_rolling_metrics(enhanced_df, row['Supplier_ID'], row['PO_Date'], 90)\n",
        "\n",
        "    rolling_features.append({\n",
        "        'PO_Number': row['PO_Number'],\n",
        "        'Supplier_30d_OTD': metrics_30['otd_rate'],\n",
        "        'Supplier_30d_Orders': metrics_30['orders_count'],\n",
        "        'Supplier_30d_AvgDelay': metrics_30['avg_delay'] if not pd.isna(metrics_30['avg_delay']) else 0,\n",
        "        'Supplier_90d_OTD': metrics_90['otd_rate'],\n",
        "        'Supplier_90d_Orders': metrics_90['orders_count'],\n",
        "        'Supplier_90d_DelayVar': metrics_90['delay_variance'] if not pd.isna(metrics_90['delay_variance']) else 0,\n",
        "    })\n",
        "\n",
        "rolling_df = pd.DataFrame(rolling_features)\n",
        "enhanced_df = enhanced_df.merge(rolling_df, on='PO_Number')\n",
        "\n",
        "print(\"✅ Rolling performance features created\")\n",
        "print(f\"   • 30-day supplier OTD rates calculated\")\n",
        "print(f\"   • 90-day supplier performance variance calculated\")\n",
        "\n",
        "# Feature Engineering: Temporal and Contextual Features\n",
        "print(\"\\n🕒 Creating Temporal and Contextual Features...\")\n",
        "\n",
        "# Extract temporal features\n",
        "enhanced_df['PO_Month'] = enhanced_df['PO_Date'].dt.month\n",
        "enhanced_df['PO_Quarter'] = enhanced_df['PO_Date'].dt.quarter\n",
        "enhanced_df['PO_DayOfWeek'] = enhanced_df['PO_Date'].dt.dayofweek\n",
        "enhanced_df['PO_WeekOfYear'] = enhanced_df['PO_Date'].dt.isocalendar().week\n",
        "\n",
        "# Seasonal indicators (construction industry patterns)\n",
        "enhanced_df['Is_Peak_Season'] = enhanced_df['PO_Month'].isin([3, 4, 5, 9, 10, 11])\n",
        "enhanced_df['Is_Low_Season'] = enhanced_df['PO_Month'].isin([12, 1, 2])\n",
        "\n",
        "# Order complexity features\n",
        "enhanced_df['Order_Size_Category'] = pd.cut(enhanced_df['Quantity_Ordered'],\n",
        "                                          bins=[0, 2, 5, 10, float('inf')],\n",
        "                                          labels=['Small', 'Medium', 'Large', 'XLarge'])\n",
        "\n",
        "enhanced_df['Order_Value_Category'] = pd.cut(enhanced_df['Order_Value_INR'],\n",
        "                                           bins=[0, 100000, 500000, 1000000, float('inf')],\n",
        "                                           labels=['Low', 'Medium', 'High', 'Premium'])\n",
        "\n",
        "# Part and supplier risk features\n",
        "criticality_risk = {'A': 3, 'B': 2, 'C': 1}\n",
        "enhanced_df['Part_Risk_Score'] = enhanced_df['Criticality'].map(criticality_risk)\n",
        "\n",
        "rating_risk = {'AAA': 1, 'AA+': 2, 'AA': 3, 'AA-': 4, 'A+': 5, 'A': 6}\n",
        "enhanced_df['Financial_Risk_Score'] = enhanced_df['Financial_Rating'].map(rating_risk)\n",
        "\n",
        "# Lead time risk indicator\n",
        "enhanced_df['Lead_Time_Risk'] = (enhanced_df['Promised_Lead_Time'] > enhanced_df['Promised_Lead_Time'].median()).astype(int)\n",
        "\n",
        "print(\"✅ Temporal and contextual features created\")\n",
        "print(f\"   • Seasonal patterns identified\")\n",
        "print(f\"   • Order complexity categorized\")\n",
        "print(f\"   • Risk scores calculated\")\n",
        "\n",
        "# Display sample of enhanced features\n",
        "print(\"\\n📋 Sample Enhanced Features:\")\n",
        "feature_cols = ['PO_Number', 'Supplier_ID', 'Criticality', 'Supplier_30d_OTD', 'Part_Risk_Score',\n",
        "                'Is_Peak_Season', 'Order_Size_Category', 'Delay_Days', 'Is_Late']\n",
        "print(enhanced_df[feature_cols].head(8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jtZQfQm-nQG",
        "outputId": "603a9c62-aa7e-474e-c40c-6b1663ff965d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔧 Step 3: Feature Engineering for Risk Analysis\n",
            "==================================================\n",
            "\n",
            "📈 Why Feature Engineering?\n",
            "Feature engineering transforms raw data into meaningful predictors for risk models.\n",
            "For supplier risk analysis, we need features that capture:\n",
            "- Historical performance patterns\n",
            "- Supplier characteristics and reliability\n",
            "- Order complexity and urgency\n",
            "- Seasonal and temporal patterns\n",
            "\n",
            "🔗 Creating Enhanced Dataset...\n",
            "✅ Enhanced dataset created with 20 features\n",
            "\n",
            "📊 Creating Historical Performance Features...\n",
            "✅ Rolling performance features created\n",
            "   • 30-day supplier OTD rates calculated\n",
            "   • 90-day supplier performance variance calculated\n",
            "\n",
            "🕒 Creating Temporal and Contextual Features...\n",
            "✅ Temporal and contextual features created\n",
            "   • Seasonal patterns identified\n",
            "   • Order complexity categorized\n",
            "   • Risk scores calculated\n",
            "\n",
            "📋 Sample Enhanced Features:\n",
            "  PO_Number Supplier_ID Criticality  Supplier_30d_OTD  Part_Risk_Score  \\\n",
            "0  PO001000      SUP105           C               0.5                1   \n",
            "1  PO001001      SUP107           A               0.5                3   \n",
            "2  PO001002      SUP105           B               1.0                2   \n",
            "3  PO001003      SUP110           B               0.5                2   \n",
            "4  PO001004      SUP111           B               0.5                2   \n",
            "5  PO001005      SUP100           C               0.5                1   \n",
            "6  PO001006      SUP107           A               1.0                3   \n",
            "7  PO001007      SUP109           A               0.5                3   \n",
            "\n",
            "   Is_Peak_Season Order_Size_Category  Delay_Days  Is_Late  \n",
            "0           False               Large          -2    False  \n",
            "1           False              Medium          -3    False  \n",
            "2           False               Small           1     True  \n",
            "3           False               Small          -1    False  \n",
            "4           False               Large          -3    False  \n",
            "5           False               Small           0    False  \n",
            "6           False               Small          -3    False  \n",
            "7           False               Small          -2    False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Predictive Modeling for Delivery Risk\n",
        "print(\"\\n🤖 Step 4: Predictive Modeling for Delivery Risk\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\n🎯 Why Predictive Modeling?\")\n",
        "print(\"Predictive models help us:\")\n",
        "print(\"- Identify high-risk purchase orders BEFORE delays occur\")\n",
        "print(\"- Quantify the probability of late delivery\")\n",
        "print(\"- Understand which factors drive delivery risks\")\n",
        "print(\"- Enable proactive risk mitigation\")\n",
        "\n",
        "# Prepare data for modeling\n",
        "print(\"\\n🔧 Preparing Data for Machine Learning...\")\n",
        "\n",
        "# Select features for the model\n",
        "model_features = [\n",
        "    'Promised_Lead_Time', 'Quantity_Ordered', 'Order_Value_INR',\n",
        "    'Part_Risk_Score', 'Financial_Risk_Score', 'Years_Partnership',\n",
        "    'Supplier_30d_OTD', 'Supplier_90d_OTD', 'Supplier_90d_DelayVar',\n",
        "    'Is_Peak_Season', 'PO_Month', 'PO_DayOfWeek', 'Lead_Time_Risk'\n",
        "]\n",
        "\n",
        "# Create feature matrix\n",
        "X = enhanced_df[model_features].copy()\n",
        "\n",
        "# Handle categorical variables\n",
        "X['Is_Peak_Season'] = X['Is_Peak_Season'].astype(int)\n",
        "X['Lead_Time_Risk'] = X['Lead_Time_Risk'].astype(int)\n",
        "\n",
        "# Fill any missing values\n",
        "X = X.fillna(0)\n",
        "\n",
        "# Target variable: Late delivery (binary)\n",
        "y_binary = enhanced_df['Is_Late'].astype(int)\n",
        "\n",
        "# Target variable: Delay days (regression)\n",
        "y_delay = enhanced_df['Delay_Days'].copy()\n",
        "\n",
        "print(f\"✅ Feature matrix prepared: {X.shape}\")\n",
        "print(f\"   • Features: {len(model_features)} predictive variables\")\n",
        "print(f\"   • Target distribution - Late deliveries: {y_binary.mean():.1%}\")\n",
        "\n",
        "# Split data for training and testing\n",
        "X_train, X_test, y_train_binary, y_test_binary = train_test_split(\n",
        "    X, y_binary, test_size=0.3, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "X_train_delay, X_test_delay, y_train_delay, y_test_delay = train_test_split(\n",
        "    X, y_delay, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"✅ Data split - Training: {X_train.shape[0]}, Testing: {X_test.shape[0]}\")\n",
        "\n",
        "# Model 1: Binary Classification - Will it be late?\n",
        "print(\"\\n🎲 Building Binary Classification Model (Late vs On-Time)...\")\n",
        "\n",
        "# Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42,\n",
        "    class_weight='balanced'  # Handle class imbalance\n",
        ")\n",
        "\n",
        "rf_classifier.fit(X_train, y_train_binary)\n",
        "\n",
        "# Predictions\n",
        "y_pred_binary = rf_classifier.predict(X_test)\n",
        "y_pred_proba = rf_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Model performance\n",
        "auc_score = roc_auc_score(y_test_binary, y_pred_proba)\n",
        "print(f\"✅ Binary Classification Model Performance:\")\n",
        "print(f\"   • AUC Score: {auc_score:.3f}\")\n",
        "print(f\"   • Accuracy: {(y_pred_binary == y_test_binary).mean():.3f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': model_features,\n",
        "    'Importance': rf_classifier.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "print(f\"\\n📊 Top 5 Most Important Features for Delay Prediction:\")\n",
        "for idx, row in feature_importance.head(5).iterrows():\n",
        "    print(f\"   {idx+1}. {row['Feature']}: {row['Importance']:.3f}\")\n",
        "\n",
        "# Model 2: Logistic Regression for Interpretability\n",
        "print(\"\\n📈 Building Logistic Regression Model (for interpretability)...\")\n",
        "\n",
        "# Scale features for logistic regression\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "lr_classifier = LogisticRegression(random_state=42, class_weight='balanced')\n",
        "lr_classifier.fit(X_train_scaled, y_train_binary)\n",
        "\n",
        "# Logistic regression predictions\n",
        "y_pred_lr = lr_classifier.predict(X_test_scaled)\n",
        "y_pred_lr_proba = lr_classifier.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "auc_lr = roc_auc_score(y_test_binary, y_pred_lr_proba)\n",
        "print(f\"✅ Logistic Regression Performance:\")\n",
        "print(f\"   • AUC Score: {auc_lr:.3f}\")\n",
        "print(f\"   • Accuracy: {(y_pred_lr == y_test_binary).mean():.3f}\")\n",
        "\n",
        "# Extract coefficients (risk factors)\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': model_features,\n",
        "    'Coefficient': lr_classifier.coef_[0],\n",
        "    'Risk_Impact': ['Increases Risk' if x > 0 else 'Reduces Risk' for x in lr_classifier.coef_[0]]\n",
        "}).sort_values('Coefficient', ascending=False, key=abs)\n",
        "\n",
        "print(f\"\\n📊 Top Risk Factors (Logistic Regression Coefficients):\")\n",
        "for idx, row in coefficients.head(5).iterrows():\n",
        "    print(f\"   • {row['Feature']}: {row['Coefficient']:.3f} ({row['Risk_Impact']})\")\n",
        "\n",
        "# Save model predictions for further analysis\n",
        "enhanced_df['Delay_Probability_RF'] = 0.0\n",
        "enhanced_df['Delay_Probability_LR'] = 0.0\n",
        "\n",
        "# Predict on full dataset\n",
        "enhanced_df.loc[X_test.index, 'Delay_Probability_RF'] = y_pred_proba\n",
        "enhanced_df.loc[X_test.index, 'Delay_Probability_LR'] = y_pred_lr_proba\n",
        "\n",
        "print(\"\\n✅ Predictive models completed and saved to dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74zwiB-vArRv",
        "outputId": "d7bfbf37-61b0-4918-befa-cca846642480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🤖 Step 4: Predictive Modeling for Delivery Risk\n",
            "==================================================\n",
            "\n",
            "🎯 Why Predictive Modeling?\n",
            "Predictive models help us:\n",
            "- Identify high-risk purchase orders BEFORE delays occur\n",
            "- Quantify the probability of late delivery\n",
            "- Understand which factors drive delivery risks\n",
            "- Enable proactive risk mitigation\n",
            "\n",
            "🔧 Preparing Data for Machine Learning...\n",
            "✅ Feature matrix prepared: (1654, 13)\n",
            "   • Features: 13 predictive variables\n",
            "   • Target distribution - Late deliveries: 22.3%\n",
            "✅ Data split - Training: 1157, Testing: 497\n",
            "\n",
            "🎲 Building Binary Classification Model (Late vs On-Time)...\n",
            "✅ Binary Classification Model Performance:\n",
            "   • AUC Score: 0.620\n",
            "   • Accuracy: 0.767\n",
            "\n",
            "📊 Top 5 Most Important Features for Delay Prediction:\n",
            "   9. Supplier_90d_DelayVar: 0.169\n",
            "   8. Supplier_90d_OTD: 0.149\n",
            "   3. Order_Value_INR: 0.139\n",
            "   7. Supplier_30d_OTD: 0.093\n",
            "   12. PO_DayOfWeek: 0.085\n",
            "\n",
            "📈 Building Logistic Regression Model (for interpretability)...\n",
            "✅ Logistic Regression Performance:\n",
            "   • AUC Score: 0.610\n",
            "   • Accuracy: 0.579\n",
            "\n",
            "📊 Top Risk Factors (Logistic Regression Coefficients):\n",
            "   • Supplier_90d_OTD: -0.350 (Reduces Risk)\n",
            "   • Supplier_30d_OTD: 0.212 (Increases Risk)\n",
            "   • Financial_Risk_Score: -0.194 (Reduces Risk)\n",
            "   • Years_Partnership: -0.192 (Reduces Risk)\n",
            "   • Part_Risk_Score: -0.149 (Reduces Risk)\n",
            "\n",
            "✅ Predictive models completed and saved to dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Comprehensive Risk Scoring System\n",
        "print(\"\\n🎯 Step 5: Comprehensive Risk Scoring System\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\n🔍 Why Risk Scoring?\")\n",
        "print(\"Risk scoring provides:\")\n",
        "print(\"- Single composite metric combining multiple risk factors\")\n",
        "print(\"- Supplier ranking and benchmarking capability\")\n",
        "print(\"- Clear categorization for decision making\")\n",
        "print(\"- Tracking risk evolution over time\")\n",
        "\n",
        "# Calculate comprehensive supplier risk scores\n",
        "print(\"\\n📊 Calculating Supplier Risk Scores...\")\n",
        "\n",
        "def calculate_supplier_risk_score(supplier_id, df):\n",
        "    \"\"\"Calculate comprehensive risk score for a supplier\"\"\"\n",
        "    supplier_data = df[df['Supplier_ID'] == supplier_id]\n",
        "\n",
        "    if len(supplier_data) == 0:\n",
        "        return {\n",
        "            'Supplier_ID': supplier_id,\n",
        "            'Risk_Score': 50,  # Neutral score\n",
        "            'Risk_Category': 'Unknown'\n",
        "        }\n",
        "\n",
        "    # Performance metrics (40% weight)\n",
        "    otd_performance = supplier_data['Is_On_Time'].mean()\n",
        "    avg_delay = supplier_data[supplier_data['Is_Late']]['Delay_Days'].mean()\n",
        "    avg_delay = avg_delay if not pd.isna(avg_delay) else 0\n",
        "\n",
        "    performance_score = (1 - otd_performance) * 40 + min(avg_delay * 2, 20)\n",
        "\n",
        "    # Volatility metrics (25% weight)\n",
        "    delay_std = supplier_data['Delay_Days'].std()\n",
        "    delay_std = delay_std if not pd.isna(delay_std) else 0\n",
        "    volatility_score = min(delay_std * 2, 25)\n",
        "\n",
        "    # Financial/Strategic metrics (20% weight)\n",
        "    financial_risk = supplier_data['Financial_Risk_Score'].iloc[0]\n",
        "    partnership_years = supplier_data['Years_Partnership'].iloc[0]\n",
        "\n",
        "    strategic_score = financial_risk * 2 - (partnership_years / 15) * 10\n",
        "    strategic_score = max(0, min(strategic_score, 20))\n",
        "\n",
        "    # Predictive metrics (15% weight)\n",
        "    avg_delay_prob = supplier_data['Delay_Probability_RF'].mean()\n",
        "    predictive_score = avg_delay_prob * 15\n",
        "\n",
        "    # Composite risk score (0-100 scale)\n",
        "    total_risk_score = performance_score + volatility_score + strategic_score + predictive_score\n",
        "\n",
        "    # Risk categorization\n",
        "    if total_risk_score <= 25:\n",
        "        risk_category = 'Low Risk'\n",
        "    elif total_risk_score <= 50:\n",
        "        risk_category = 'Medium Risk'\n",
        "    elif total_risk_score <= 75:\n",
        "        risk_category = 'High Risk'\n",
        "    else:\n",
        "        risk_category = 'Critical Risk'\n",
        "\n",
        "    return {\n",
        "        'Supplier_ID': supplier_id,\n",
        "        'Total_Orders': len(supplier_data),\n",
        "        'OTD_Performance': otd_performance,\n",
        "        'Avg_Delay_Days': avg_delay,\n",
        "        'Delay_Volatility': delay_std,\n",
        "        'Avg_Delay_Probability': avg_delay_prob,\n",
        "        'Total_Order_Value': supplier_data['Order_Value_INR'].sum(),\n",
        "        'Performance_Score': performance_score,\n",
        "        'Volatility_Score': volatility_score,\n",
        "        'Strategic_Score': strategic_score,\n",
        "        'Predictive_Score': predictive_score,\n",
        "        'Risk_Score': total_risk_score,\n",
        "        'Risk_Category': risk_category\n",
        "    }\n",
        "\n",
        "# Calculate risk scores for all suppliers\n",
        "supplier_risk_analysis = []\n",
        "for supplier_id in suppliers_df['Supplier_ID'].unique():\n",
        "    risk_data = calculate_supplier_risk_score(supplier_id, enhanced_df)\n",
        "    supplier_risk_analysis.append(risk_data)\n",
        "\n",
        "supplier_risk_final_df = pd.DataFrame(supplier_risk_analysis)\n",
        "supplier_risk_final_df = supplier_risk_final_df.merge(\n",
        "    suppliers_df[['Supplier_ID', 'Supplier_Name', 'Location', 'Supplier_Type']],\n",
        "    on='Supplier_ID'\n",
        ")\n",
        "\n",
        "print(\"✅ Supplier risk scores calculated\")\n",
        "\n",
        "# Display supplier risk ranking\n",
        "print(f\"\\n🏆 Supplier Risk Ranking (Top 5 by Risk Score):\")\n",
        "risk_ranking = supplier_risk_final_df.sort_values('Risk_Score', ascending=False)\n",
        "for idx, row in risk_ranking.head().iterrows():\n",
        "    print(f\"   {idx+1}. {row['Supplier_Name']} ({row['Supplier_ID']})\")\n",
        "    print(f\"      Risk Score: {row['Risk_Score']:.1f} | Category: {row['Risk_Category']}\")\n",
        "    print(f\"      OTD: {row['OTD_Performance']:.1%} | Avg Delay: {row['Avg_Delay_Days']:.1f} days\")\n",
        "\n",
        "# Step 6: Part-Level Risk Analysis\n",
        "print(\"\\n🔧 Step 6: Part-Level Risk Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"\\n⚙️ Why Part-Level Analysis?\")\n",
        "print(\"Part analysis identifies:\")\n",
        "print(\"- Critical components with supply risks\")\n",
        "print(\"- Parts requiring safety stock adjustments\")\n",
        "print(\"- Components needing supplier diversification\")\n",
        "\n",
        "def calculate_part_risk_metrics(part_id, df):\n",
        "    \"\"\"Calculate risk metrics for a specific part\"\"\"\n",
        "    part_data = df[df['Part_ID'] == part_id]\n",
        "\n",
        "    if len(part_data) == 0:\n",
        "        return None\n",
        "\n",
        "    # Basic metrics\n",
        "    total_orders = len(part_data)\n",
        "    otd_performance = part_data['Is_On_Time'].mean()\n",
        "    avg_delay = part_data[part_data['Is_Late']]['Delay_Days'].mean()\n",
        "    avg_delay = avg_delay if not pd.isna(avg_delay) else 0\n",
        "\n",
        "    # Supplier diversity\n",
        "    supplier_count = part_data['Supplier_ID'].nunique()\n",
        "    primary_supplier_share = part_data.groupby('Supplier_ID').size().max() / total_orders\n",
        "\n",
        "    # Financial exposure\n",
        "    total_order_value = part_data['Order_Value_INR'].sum()\n",
        "    avg_order_value = part_data['Order_Value_INR'].mean()\n",
        "\n",
        "    # Risk concentration\n",
        "    criticality = part_data['Criticality'].iloc[0]\n",
        "    criticality_multiplier = {'A': 3, 'B': 2, 'C': 1}[criticality]\n",
        "\n",
        "    # Composite risk score for parts\n",
        "    supply_risk = (1 - otd_performance) * 30\n",
        "    concentration_risk = primary_supplier_share * 20\n",
        "    criticality_risk = criticality_multiplier * 10\n",
        "    delay_risk = min(avg_delay * 3, 20)\n",
        "\n",
        "    part_risk_score = supply_risk + concentration_risk + criticality_risk + delay_risk\n",
        "\n",
        "    return {\n",
        "        'Part_ID': part_id,\n",
        "        'Part_Name': parts_df[parts_df['Part_ID'] == part_id]['Part_Name'].iloc[0],\n",
        "        'Category': part_data['Category'].iloc[0],\n",
        "        'Criticality': criticality,\n",
        "        'Total_Orders': total_orders,\n",
        "        'Supplier_Count': supplier_count,\n",
        "        'Primary_Supplier_Share': primary_supplier_share,\n",
        "        'OTD_Performance': otd_performance,\n",
        "        'Avg_Delay_Days': avg_delay,\n",
        "        'Total_Order_Value': total_order_value,\n",
        "        'Avg_Order_Value': avg_order_value,\n",
        "        'Part_Risk_Score': part_risk_score,\n",
        "        'Risk_Category': 'High Risk' if part_risk_score > 50 else 'Medium Risk' if part_risk_score > 25 else 'Low Risk'\n",
        "    }\n",
        "\n",
        "# Calculate part risk metrics\n",
        "part_risk_analysis = []\n",
        "for part_id in parts_df['Part_ID'].unique():\n",
        "    part_risk_data = calculate_part_risk_metrics(part_id, enhanced_df)\n",
        "    if part_risk_data:\n",
        "        part_risk_analysis.append(part_risk_data)\n",
        "\n",
        "part_risk_df = pd.DataFrame(part_risk_analysis)\n",
        "\n",
        "print(\"✅ Part-level risk analysis completed\")\n",
        "\n",
        "# Display high-risk parts\n",
        "print(f\"\\n⚠️ Top 5 Highest Risk Parts:\")\n",
        "high_risk_parts = part_risk_df.sort_values('Part_Risk_Score', ascending=False)\n",
        "for idx, row in high_risk_parts.head().iterrows():\n",
        "    print(f\"   {idx+1}. {row['Part_Name']} ({row['Part_ID']})\")\n",
        "    print(f\"      Risk Score: {row['Part_Risk_Score']:.1f} | Criticality: {row['Criticality']}\")\n",
        "    print(f\"      Suppliers: {row['Supplier_Count']} | OTD: {row['OTD_Performance']:.1%}\")\n",
        "\n",
        "print(f\"\\n📊 Part Risk Distribution:\")\n",
        "print(part_risk_df['Risk_Category'].value_counts())\n",
        "\n",
        "print(f\"\\n💰 Financial Exposure by Risk Category:\")\n",
        "financial_by_risk = part_risk_df.groupby('Risk_Category')['Total_Order_Value'].sum()\n",
        "for category, value in financial_by_risk.items():\n",
        "    print(f\"   • {category}: ₹{value:,.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwe1xhwOB33S",
        "outputId": "4282886a-4641-4269-a4b4-346261fde5f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Step 5: Comprehensive Risk Scoring System\n",
            "==================================================\n",
            "\n",
            "🔍 Why Risk Scoring?\n",
            "Risk scoring provides:\n",
            "- Single composite metric combining multiple risk factors\n",
            "- Supplier ranking and benchmarking capability\n",
            "- Clear categorization for decision making\n",
            "- Tracking risk evolution over time\n",
            "\n",
            "📊 Calculating Supplier Risk Scores...\n",
            "✅ Supplier risk scores calculated\n",
            "\n",
            "🏆 Supplier Risk Ranking (Top 5 by Risk Score):\n",
            "   15. Bajaj Auto Ltd (SUP114)\n",
            "      Risk Score: 45.4 | Category: Medium Risk\n",
            "      OTD: 54.4% | Avg Delay: 6.0 days\n",
            "   7. Action Construction Equipment (SUP106)\n",
            "      Risk Score: 38.4 | Category: Medium Risk\n",
            "      OTD: 50.6% | Avg Delay: 3.9 days\n",
            "   8. Escorts Construction Equipment (SUP107)\n",
            "      Risk Score: 32.0 | Category: Medium Risk\n",
            "      OTD: 76.4% | Avg Delay: 4.5 days\n",
            "   9. Volvo Construction Equipment (SUP108)\n",
            "      Risk Score: 29.6 | Category: Medium Risk\n",
            "      OTD: 72.9% | Avg Delay: 4.4 days\n",
            "   6. Mahindra Construction Equipment (SUP105)\n",
            "      Risk Score: 29.0 | Category: Medium Risk\n",
            "      OTD: 67.7% | Avg Delay: 2.3 days\n",
            "\n",
            "🔧 Step 6: Part-Level Risk Analysis\n",
            "========================================\n",
            "\n",
            "⚙️ Why Part-Level Analysis?\n",
            "Part analysis identifies:\n",
            "- Critical components with supply risks\n",
            "- Parts requiring safety stock adjustments\n",
            "- Components needing supplier diversification\n",
            "✅ Part-level risk analysis completed\n",
            "\n",
            "⚠️ Top 5 Highest Risk Parts:\n",
            "   7. Fuel Filter (PT1006)\n",
            "      Risk Score: 68.1 | Criticality: A\n",
            "      Suppliers: 2 | OTD: 72.5%\n",
            "   3. Hydraulic Filter (PT1002)\n",
            "      Risk Score: 62.2 | Criticality: A\n",
            "      Suppliers: 2 | OTD: 67.8%\n",
            "   4. Hydraulic Hose (PT1003)\n",
            "      Risk Score: 62.1 | Criticality: A\n",
            "      Suppliers: 2 | OTD: 67.7%\n",
            "   28. Transmission Filter (PT1027)\n",
            "      Risk Score: 61.4 | Criticality: A\n",
            "      Suppliers: 2 | OTD: 64.5%\n",
            "   13. Track Pad (PT1012)\n",
            "      Risk Score: 61.4 | Criticality: B\n",
            "      Suppliers: 1 | OTD: 73.1%\n",
            "\n",
            "📊 Part Risk Distribution:\n",
            "Risk_Category\n",
            "High Risk      20\n",
            "Medium Risk    12\n",
            "Name: count, dtype: int64\n",
            "\n",
            "💰 Financial Exposure by Risk Category:\n",
            "   • High Risk: ₹251,227,169\n",
            "   • Medium Risk: ₹74,990,084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Monte Carlo Simulation for Fill Rate Impact\n",
        "print(\"\\n🎲 Step 7: Monte Carlo Simulation for Fill Rate Impact\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "print(\"\\n🎯 Why Monte Carlo Simulation?\")\n",
        "print(\"Monte Carlo simulation helps us:\")\n",
        "print(\"- Model uncertainty in delivery times and demand\")\n",
        "print(\"- Estimate probability of stockouts and production delays\")\n",
        "print(\"- Quantify financial impact under different scenarios\")\n",
        "print(\"- Test effectiveness of risk mitigation strategies\")\n",
        "\n",
        "# Generate production requirements (simplified for simulation)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Create a simplified production schedule\n",
        "production_scenarios = []\n",
        "simulation_start = pd.Timestamp('2025-02-01')\n",
        "\n",
        "for week in range(12):  # 12-week simulation\n",
        "    week_start = simulation_start + pd.Timedelta(weeks=week)\n",
        "\n",
        "    # Weekly production requirements (realistic for excavator manufacturing)\n",
        "    weekly_production = {\n",
        "        'EX200': np.random.poisson(6),  # 6 units average per week\n",
        "        'EX350': np.random.poisson(4),  # 4 units average per week\n",
        "        'EX470': np.random.poisson(3),  # 3 units average per week\n",
        "        'EX700': np.random.poisson(2)   # 2 units average per week\n",
        "    }\n",
        "\n",
        "    production_scenarios.append({\n",
        "        'Week': week + 1,\n",
        "        'Week_Start': week_start,\n",
        "        'EX200_Units': weekly_production['EX200'],\n",
        "        'EX350_Units': weekly_production['EX350'],\n",
        "        'EX470_Units': weekly_production['EX470'],\n",
        "        'EX700_Units': weekly_production['EX700'],\n",
        "        'Total_Units': sum(weekly_production.values())\n",
        "    })\n",
        "\n",
        "production_forecast_df = pd.DataFrame(production_scenarios)\n",
        "print(f\"✅ Production forecast created: {len(production_forecast_df)} weeks\")\n",
        "\n",
        "# Define parts requirements per excavator model (Bill of Materials)\n",
        "bom_requirements = {\n",
        "    'EX200': {'PT1000': 1, 'PT1001': 2, 'PT1002': 1, 'PT1003': 2, 'PT1004': 1},\n",
        "    'EX350': {'PT1000': 1, 'PT1001': 2, 'PT1002': 2, 'PT1003': 3, 'PT1004': 2, 'PT1005': 1},\n",
        "    'EX700': {'PT1000': 2, 'PT1001': 3, 'PT1002': 2, 'PT1003': 4, 'PT1004': 2, 'PT1005': 2, 'PT1006': 1}\n",
        "}\n",
        "\n",
        "def simulate_delivery_scenario(supplier_id, part_id, order_date, num_simulations=1000):\n",
        "    \"\"\"\n",
        "    Simulate delivery performance for a supplier-part combination\n",
        "    Returns distribution of actual delivery dates\n",
        "    \"\"\"\n",
        "    # Get supplier characteristics\n",
        "    supplier_info = suppliers_df[suppliers_df['Supplier_ID'] == supplier_id].iloc[0]\n",
        "\n",
        "    # Get historical performance for this supplier\n",
        "    supplier_pos = enhanced_df[enhanced_df['Supplier_ID'] == supplier_id]\n",
        "\n",
        "    if len(supplier_pos) > 0:\n",
        "        # Use historical delay distribution\n",
        "        historical_delays = supplier_pos['Delay_Days'].values\n",
        "        otd_rate = supplier_pos['Is_On_Time'].mean()\n",
        "    else:\n",
        "        # Use supplier baseline performance\n",
        "        otd_rate = supplier_info['Historical_OTD_Pct']\n",
        "        historical_delays = np.random.normal(0, supplier_info['Lead_Time_Variance'], 100)\n",
        "\n",
        "    # Simulate delivery delays\n",
        "    simulated_delays = []\n",
        "    base_lead_time = supplier_info['Avg_Lead_Time_Days']\n",
        "\n",
        "    for _ in range(num_simulations):\n",
        "        if np.random.random() < otd_rate:\n",
        "            # On-time delivery (can be early)\n",
        "            delay = np.random.choice([-2, -1, 0], p=[0.2, 0.3, 0.5])\n",
        "        else:\n",
        "            # Late delivery - sample from historical delays\n",
        "            if len(historical_delays[historical_delays > 0]) > 0:\n",
        "                delay = np.random.choice(historical_delays[historical_delays > 0])\n",
        "            else:\n",
        "                delay = np.random.randint(1, 10)\n",
        "\n",
        "        # Add lead time variance\n",
        "        variance = np.random.normal(0, supplier_info['Lead_Time_Variance'])\n",
        "        total_delay = delay + variance\n",
        "\n",
        "        delivery_date = order_date + pd.Timedelta(days=base_lead_time + total_delay)\n",
        "        simulated_delays.append(total_delay)\n",
        "\n",
        "    return simulated_delays\n",
        "\n",
        "print(\"\\n🎲 Running Monte Carlo Simulation...\")\n",
        "\n",
        "# Simulation parameters\n",
        "num_simulations = 500\n",
        "simulation_results = []\n",
        "\n",
        "# For each week of production, simulate parts delivery\n",
        "for _, week_row in production_forecast_df.head(8).iterrows():  # Simulate first 8 weeks\n",
        "    week_start = week_row['Week_Start']\n",
        "    week_num = week_row['Week']\n",
        "\n",
        "    # Calculate parts needed for this week's production\n",
        "    parts_needed = {}\n",
        "\n",
        "    # EX200 requirements\n",
        "    for part_id, qty_per_unit in bom_requirements['EX200'].items():\n",
        "        parts_needed[part_id] = parts_needed.get(part_id, 0) + (week_row['EX200_Units'] * qty_per_unit)\n",
        "\n",
        "    # EX350 requirements (if defined in BOM)\n",
        "    if week_row['EX350_Units'] > 0:\n",
        "        for part_id, qty_per_unit in bom_requirements['EX350'].items():\n",
        "            parts_needed[part_id] = parts_needed.get(part_id, 0) + (week_row['EX350_Units'] * qty_per_unit)\n",
        "\n",
        "    # Order date (parts ordered 3 weeks before production)\n",
        "    order_date = week_start - pd.Timedelta(weeks=3)\n",
        "\n",
        "    # Simulate delivery for each required part\n",
        "    week_simulation_results = []\n",
        "\n",
        "    for part_id, quantity_needed in parts_needed.items():\n",
        "        # Get primary supplier for this part (simplified)\n",
        "        primary_supplier = enhanced_df[enhanced_df['Part_ID'] == part_id]['Supplier_ID'].iloc[0]\n",
        "\n",
        "        # Simulate delivery delays\n",
        "        delivery_delays = simulate_delivery_scenario(primary_supplier, part_id, order_date, num_simulations)\n",
        "\n",
        "        # Calculate delivery date distribution\n",
        "        delivery_dates = [order_date + pd.Timedelta(days=22 + delay) for delay in delivery_delays]\n",
        "\n",
        "        # Check if parts arrive on time for production (before week_start)\n",
        "        on_time_deliveries = sum([1 for date in delivery_dates if date <= week_start])\n",
        "        on_time_rate = on_time_deliveries / num_simulations\n",
        "\n",
        "        # Average delay from required date\n",
        "        avg_delay_from_required = np.mean([(date - week_start).days for date in delivery_dates])\n",
        "\n",
        "        week_simulation_results.append({\n",
        "            'Week': week_num,\n",
        "            'Week_Start': week_start,\n",
        "            'Part_ID': part_id,\n",
        "            'Supplier_ID': primary_supplier,\n",
        "            'Quantity_Needed': quantity_needed,\n",
        "            'On_Time_Rate': on_time_rate,\n",
        "            'Avg_Delay_From_Required': avg_delay_from_required,\n",
        "            'Stockout_Risk': 1 - on_time_rate\n",
        "        })\n",
        "\n",
        "    simulation_results.extend(week_simulation_results)\n",
        "\n",
        "    print(f\"   ✅ Week {week_num} simulation completed - {len(parts_needed)} parts analyzed\")\n",
        "\n",
        "simulation_results_df = pd.DataFrame(simulation_results)\n",
        "\n",
        "print(f\"✅ Monte Carlo simulation completed\")\n",
        "print(f\"   • Simulated {num_simulations} scenarios per part-week combination\")\n",
        "print(f\"   • Analyzed {len(simulation_results)} part-week requirements\")\n",
        "\n",
        "# Calculate fill rate impact\n",
        "print(f\"\\n📊 Fill Rate Impact Analysis:\")\n",
        "\n",
        "# Overall metrics\n",
        "avg_on_time_rate = simulation_results_df['On_Time_Rate'].mean()\n",
        "high_risk_parts = len(simulation_results_df[simulation_results_df['Stockout_Risk'] > 0.3])\n",
        "total_part_requirements = len(simulation_results_df)\n",
        "\n",
        "print(f\"   • Average On-Time Rate: {avg_on_time_rate:.1%}\")\n",
        "print(f\"   • High Stockout Risk (>30%): {high_risk_parts}/{total_part_requirements} requirements\")\n",
        "print(f\"   • Average Delay from Required Date: {simulation_results_df['Avg_Delay_From_Required'].mean():.1f} days\")\n",
        "\n",
        "# Week-by-week fill rate\n",
        "weekly_fill_rate = simulation_results_df.groupby('Week').agg({\n",
        "    'On_Time_Rate': 'mean',\n",
        "    'Stockout_Risk': 'max',\n",
        "    'Quantity_Needed': 'sum'\n",
        "}).round(3)\n",
        "\n",
        "print(f\"\\n📅 Weekly Fill Rate Forecast:\")\n",
        "print(weekly_fill_rate.head(8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFIbxl5wCStv",
        "outputId": "149995f7-ce30-4f10-f04c-2ffd06006f20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎲 Step 7: Monte Carlo Simulation for Fill Rate Impact\n",
            "=======================================================\n",
            "\n",
            "🎯 Why Monte Carlo Simulation?\n",
            "Monte Carlo simulation helps us:\n",
            "- Model uncertainty in delivery times and demand\n",
            "- Estimate probability of stockouts and production delays\n",
            "- Quantify financial impact under different scenarios\n",
            "- Test effectiveness of risk mitigation strategies\n",
            "✅ Production forecast created: 12 weeks\n",
            "\n",
            "🎲 Running Monte Carlo Simulation...\n",
            "   ✅ Week 1 simulation completed - 6 parts analyzed\n",
            "   ✅ Week 2 simulation completed - 6 parts analyzed\n",
            "   ✅ Week 3 simulation completed - 6 parts analyzed\n",
            "   ✅ Week 4 simulation completed - 6 parts analyzed\n",
            "   ✅ Week 5 simulation completed - 5 parts analyzed\n",
            "   ✅ Week 6 simulation completed - 6 parts analyzed\n",
            "   ✅ Week 7 simulation completed - 6 parts analyzed\n",
            "   ✅ Week 8 simulation completed - 6 parts analyzed\n",
            "✅ Monte Carlo simulation completed\n",
            "   • Simulated 500 scenarios per part-week combination\n",
            "   • Analyzed 47 part-week requirements\n",
            "\n",
            "📊 Fill Rate Impact Analysis:\n",
            "   • Average On-Time Rate: 41.4%\n",
            "   • High Stockout Risk (>30%): 47/47 requirements\n",
            "   • Average Delay from Required Date: 1.3 days\n",
            "\n",
            "📅 Weekly Fill Rate Forecast:\n",
            "      On_Time_Rate  Stockout_Risk  Quantity_Needed\n",
            "Week                                              \n",
            "1            0.413          0.626               75\n",
            "2            0.396          0.630               79\n",
            "3            0.405          0.660               68\n",
            "4            0.425          0.622               74\n",
            "5            0.414          0.606               42\n",
            "6            0.414          0.632               90\n",
            "7            0.418          0.624               58\n",
            "8            0.430          0.630              121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Optimization Recommendations and Business Intelligence Outputs\n",
        "print(\"\\n🎯 Step 8: Optimization Recommendations & BI Outputs\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "print(\"\\n💡 Why Optimization Recommendations?\")\n",
        "print(\"Optimization provides:\")\n",
        "print(\"- Actionable strategies to reduce supply risk\")\n",
        "print(\"- Cost-benefit analysis of mitigation options\")\n",
        "print(\"- Prioritized list of interventions\")\n",
        "print(\"- ROI estimates for risk reduction initiatives\")\n",
        "\n",
        "# Safety Stock Optimization\n",
        "print(\"\\n📦 Safety Stock Optimization Analysis...\")\n",
        "\n",
        "def calculate_optimal_safety_stock(part_id, current_stock=None):\n",
        "    \"\"\"Calculate optimal safety stock based on demand variability and supplier reliability\"\"\"\n",
        "\n",
        "    # Get part characteristics\n",
        "    part_info = parts_df[parts_df['Part_ID'] == part_id].iloc[0]\n",
        "    part_orders = enhanced_df[enhanced_df['Part_ID'] == part_id]\n",
        "\n",
        "    if len(part_orders) == 0:\n",
        "        return None\n",
        "\n",
        "    # Calculate demand characteristics\n",
        "    weekly_demand_mean = part_orders['Quantity_Ordered'].mean() * 0.25  # Convert to weekly\n",
        "    weekly_demand_std = part_orders['Quantity_Ordered'].std() * 0.25\n",
        "\n",
        "    # Calculate lead time characteristics\n",
        "    avg_lead_time = part_orders['Actual_Lead_Time'].mean() / 7  # Convert to weeks\n",
        "    lead_time_std = part_orders['Actual_Lead_Time'].std() / 7\n",
        "\n",
        "    # Service level targets based on criticality\n",
        "    service_levels = {'A': 0.98, 'B': 0.95, 'C': 0.90}\n",
        "    target_service_level = service_levels[part_info['Criticality']]\n",
        "\n",
        "    # Z-score for service level\n",
        "    z_scores = {0.90: 1.28, 0.95: 1.65, 0.98: 2.05}\n",
        "    z_score = z_scores[target_service_level]\n",
        "\n",
        "    # Safety stock calculation (standard formula)\n",
        "    demand_variability = weekly_demand_std * np.sqrt(avg_lead_time)\n",
        "    lead_time_variability = weekly_demand_mean * lead_time_std\n",
        "\n",
        "    total_variability = np.sqrt(demand_variability**2 + lead_time_variability**2)\n",
        "    safety_stock = z_score * total_variability\n",
        "\n",
        "    # Calculate current vs recommended difference\n",
        "    current_ss = current_stock if current_stock else safety_stock  # Default assumption\n",
        "    ss_change = safety_stock - current_ss\n",
        "\n",
        "    # Cost implications\n",
        "    unit_price = part_info['Unit_Price_INR']\n",
        "    carrying_cost_rate = 0.25  # 25% annual carrying cost\n",
        "    carrying_cost_change = ss_change * unit_price * carrying_cost_rate\n",
        "\n",
        "    # Stockout cost estimate (based on production impact)\n",
        "    criticality_impact = {'A': 100000, 'B': 50000, 'C': 20000}  # Daily production loss\n",
        "    expected_stockout_cost = criticality_impact[part_info['Criticality']] * 0.02  # 2% chance\n",
        "\n",
        "    return {\n",
        "        'Part_ID': part_id,\n",
        "        'Part_Name': part_info['Part_Name'],\n",
        "        'Criticality': part_info['Criticality'],\n",
        "        'Current_Safety_Stock': current_ss,\n",
        "        'Recommended_Safety_Stock': max(1, round(safety_stock)),\n",
        "        'Safety_Stock_Change': round(ss_change),\n",
        "        'Weekly_Demand_Mean': round(weekly_demand_mean, 1),\n",
        "        'Lead_Time_Weeks': round(avg_lead_time, 1),\n",
        "        'Target_Service_Level': target_service_level,\n",
        "        'Annual_Carrying_Cost_Change': round(carrying_cost_change),\n",
        "        'Expected_Stockout_Cost_Reduction': round(expected_stockout_cost)\n",
        "    }\n",
        "\n",
        "# Calculate safety stock recommendations\n",
        "safety_stock_recommendations = []\n",
        "for part_id in parts_df['Part_ID'].head(8):  # Top 8 parts for demo\n",
        "    ss_rec = calculate_optimal_safety_stock(part_id)\n",
        "    if ss_rec:\n",
        "        safety_stock_recommendations.append(ss_rec)\n",
        "\n",
        "safety_stock_df = pd.DataFrame(safety_stock_recommendations)\n",
        "\n",
        "print(\"✅ Safety stock optimization completed\")\n",
        "print(f\"\\n📦 Safety Stock Recommendations (Top 5):\")\n",
        "safety_stock_sorted = safety_stock_df.sort_values('Safety_Stock_Change', ascending=False)\n",
        "for idx, row in safety_stock_sorted.head().iterrows():\n",
        "    change_direction = \"Increase\" if row['Safety_Stock_Change'] > 0 else \"Decrease\"\n",
        "    print(f\"   {idx+1}. {row['Part_Name']} ({row['Criticality']}):\")\n",
        "    print(f\"      {change_direction} by {abs(row['Safety_Stock_Change']):.0f} units\")\n",
        "    print(f\"      Target Service Level: {row['Target_Service_Level']:.0%}\")\n",
        "\n",
        "# Supplier Diversification Recommendations\n",
        "print(f\"\\n🔄 Supplier Diversification Analysis...\")\n",
        "\n",
        "diversification_recommendations = []\n",
        "\n",
        "for _, part in part_risk_df.iterrows():\n",
        "    if part['Supplier_Count'] < 2 and part['Criticality'] == 'A':\n",
        "        # Critical parts with single supplier = high risk\n",
        "        primary_supplier_id = enhanced_df[enhanced_df['Part_ID'] == part['Part_ID']]['Supplier_ID'].iloc[0]\n",
        "        primary_supplier_risk = supplier_risk_final_df[supplier_risk_final_df['Supplier_ID'] == primary_supplier_id]['Risk_Score'].iloc[0]\n",
        "\n",
        "        # Find alternative suppliers (with lower risk scores)\n",
        "        alternative_suppliers = supplier_risk_final_df[\n",
        "            (supplier_risk_final_df['Risk_Score'] < primary_supplier_risk) &\n",
        "            (supplier_risk_final_df['Supplier_ID'] != primary_supplier_id)\n",
        "        ].head(2)\n",
        "\n",
        "        diversification_recommendations.append({\n",
        "            'Part_ID': part['Part_ID'],\n",
        "            'Part_Name': part['Part_Name'],\n",
        "            'Current_Supplier_Count': part['Supplier_Count'],\n",
        "            'Primary_Supplier_Risk': primary_supplier_risk,\n",
        "            'Recommended_Action': 'Dual Source',\n",
        "            'Alternative_Suppliers': ', '.join(alternative_suppliers['Supplier_Name'].tolist()),\n",
        "            'Risk_Reduction_Potential': primary_supplier_risk * 0.3  # 30% risk reduction\n",
        "        })\n",
        "\n",
        "diversification_df = pd.DataFrame(diversification_recommendations)\n",
        "\n",
        "print(\"✅ Supplier diversification analysis completed\")\n",
        "if len(diversification_df) > 0:\n",
        "    print(f\"\\n🔄 Dual Sourcing Recommendations:\")\n",
        "    for idx, row in diversification_df.iterrows():\n",
        "        print(f\"   {idx+1}. {row['Part_Name']}: Add {row['Alternative_Suppliers']}\")\n",
        "        print(f\"      Risk Reduction: {row['Risk_Reduction_Potential']:.1f} points\")\n",
        "\n",
        "# Generate Business Intelligence Export Files\n",
        "print(f\"\\n📤 Generating BI Export Files...\")\n",
        "\n",
        "# 1. Supplier Risk Scorecard (for BI dashboard)\n",
        "supplier_scorecard = supplier_risk_final_df[[\n",
        "    'Supplier_ID', 'Supplier_Name', 'Location', 'Supplier_Type',\n",
        "    'OTD_Performance', 'Avg_Delay_Days', 'Risk_Score', 'Risk_Category',\n",
        "    'Total_Orders', 'Total_Order_Value'\n",
        "]].copy()\n",
        "\n",
        "supplier_scorecard['OTD_Performance'] = (supplier_scorecard['OTD_Performance'] * 100).round(1)\n",
        "supplier_scorecard['Risk_Score'] = supplier_scorecard['Risk_Score'].round(1)\n",
        "supplier_scorecard['Total_Order_Value'] = supplier_scorecard['Total_Order_Value'].round(0)\n",
        "\n",
        "# 2. Part Risk Analysis (for BI dashboard)\n",
        "part_scorecard = part_risk_df[[\n",
        "    'Part_ID', 'Part_Name', 'Category', 'Criticality',\n",
        "    'Supplier_Count', 'OTD_Performance', 'Part_Risk_Score', 'Risk_Category',\n",
        "    'Total_Order_Value'\n",
        "]].copy()\n",
        "\n",
        "part_scorecard['OTD_Performance'] = (part_scorecard['OTD_Performance'] * 100).round(1)\n",
        "part_scorecard['Part_Risk_Score'] = part_scorecard['Part_Risk_Score'].round(1)\n",
        "\n",
        "# 3. PO Risk Predictions (for operational dashboard)\n",
        "po_predictions = enhanced_df[[\n",
        "    'PO_Number', 'PO_Date', 'Part_ID', 'Supplier_ID',\n",
        "    'Promised_Delivery_Date', 'Actual_Delivery_Date',\n",
        "    'Delay_Probability_RF', 'Delay_Days', 'Order_Value_INR', 'Is_Late'\n",
        "]].copy()\n",
        "\n",
        "po_predictions['Delay_Probability_RF'] = (po_predictions['Delay_Probability_RF'] * 100).round(1)\n",
        "po_predictions['Risk_Level'] = pd.cut(po_predictions['Delay_Probability_RF'],\n",
        "                                     bins=[0, 25, 50, 75, 100],\n",
        "                                     labels=['Low', 'Medium', 'High', 'Critical'])\n",
        "\n",
        "# 4. Fill Rate Simulation Results (for scenario analysis)\n",
        "fill_rate_forecast = simulation_results_df.copy()\n",
        "fill_rate_forecast['On_Time_Rate'] = (fill_rate_forecast['On_Time_Rate'] * 100).round(1)\n",
        "fill_rate_forecast['Stockout_Risk'] = (fill_rate_forecast['Stockout_Risk'] * 100).round(1)\n",
        "\n",
        "# 5. Optimization Recommendations Summary\n",
        "optimization_summary = {\n",
        "    'Safety_Stock_Recommendations': len(safety_stock_df),\n",
        "    'Total_Carrying_Cost_Change': safety_stock_df['Annual_Carrying_Cost_Change'].sum(),\n",
        "    'Parts_Needing_Dual_Sourcing': len(diversification_df),\n",
        "    'High_Risk_Suppliers': len(supplier_scorecard[supplier_scorecard['Risk_Category'].isin(['High Risk', 'Critical Risk'])]),\n",
        "    'High_Risk_Parts': len(part_scorecard[part_scorecard['Risk_Category'] == 'High Risk']),\n",
        "    'Average_Fill_Rate': fill_rate_forecast['On_Time_Rate'].mean(),\n",
        "    'Generation_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "}\n",
        "\n",
        "print(\"✅ BI export files prepared\")\n",
        "\n",
        "# Summary Report\n",
        "print(f\"\\n📊 PROJECT SUMMARY REPORT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"🎯 KEY FINDINGS:\")\n",
        "print(f\"   • Analyzed {len(enhanced_df)} purchase orders from {len(suppliers_df)} suppliers\")\n",
        "print(f\"   • Overall OTD Performance: {enhanced_df['Is_On_Time'].mean():.1%}\")\n",
        "print(f\"   • {len(supplier_scorecard[supplier_scorecard['Risk_Category'].isin(['High Risk', 'Critical Risk'])])} suppliers classified as high/critical risk\")\n",
        "print(f\"   • {len(part_scorecard[part_scorecard['Risk_Category'] == 'High Risk'])} parts identified as high-risk\")\n",
        "print(f\"   • Predicted fill rate: {optimization_summary['Average_Fill_Rate']:.1f}%\")\n",
        "\n",
        "print(f\"\\n💡 OPTIMIZATION RECOMMENDATIONS:\")\n",
        "print(f\"   • Adjust safety stock for {len(safety_stock_df)} critical parts\")\n",
        "print(f\"   • Implement dual sourcing for {len(diversification_df)} single-source critical parts\")\n",
        "print(f\"   • Focus supplier improvement efforts on {supplier_scorecard[supplier_scorecard['Risk_Score'] > 30].shape[0]} medium/high-risk suppliers\")\n",
        "print(f\"   • Estimated annual carrying cost impact: ₹{abs(optimization_summary['Total_Carrying_Cost_Change']):,.0f}\")\n",
        "\n",
        "print(f\"\\n📈 NEXT STEPS:\")\n",
        "print(\"   1. Deploy predictive models in production environment\")\n",
        "print(\"   2. Implement automated risk scoring dashboard\")\n",
        "print(\"   3. Establish supplier performance monitoring\")\n",
        "print(\"   4. Execute safety stock optimization plan\")\n",
        "print(\"   5. Initiate dual sourcing negotiations for critical parts\")\n",
        "\n",
        "print(f\"\\n✅ Python Analytics Pipeline Completed Successfully!\")\n",
        "print(f\"   Ready for BI Dashboard Development and Stakeholder Presentation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39gwhiC9Ca2O",
        "outputId": "81d83736-d7e6-4c0a-a4c8-0e9b9f376d97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎯 Step 8: Optimization Recommendations & BI Outputs\n",
            "=======================================================\n",
            "\n",
            "💡 Why Optimization Recommendations?\n",
            "Optimization provides:\n",
            "- Actionable strategies to reduce supply risk\n",
            "- Cost-benefit analysis of mitigation options\n",
            "- Prioritized list of interventions\n",
            "- ROI estimates for risk reduction initiatives\n",
            "\n",
            "📦 Safety Stock Optimization Analysis...\n",
            "✅ Safety stock optimization completed\n",
            "\n",
            "📦 Safety Stock Recommendations (Top 5):\n",
            "   1. Hydraulic Pump (A):\n",
            "      Decrease by 0 units\n",
            "      Target Service Level: 98%\n",
            "   2. Hydraulic Cylinder (A):\n",
            "      Decrease by 0 units\n",
            "      Target Service Level: 98%\n",
            "   3. Hydraulic Filter (A):\n",
            "      Decrease by 0 units\n",
            "      Target Service Level: 98%\n",
            "   4. Hydraulic Hose (A):\n",
            "      Decrease by 0 units\n",
            "      Target Service Level: 98%\n",
            "   5. Control Valve (A):\n",
            "      Decrease by 0 units\n",
            "      Target Service Level: 98%\n",
            "\n",
            "🔄 Supplier Diversification Analysis...\n",
            "✅ Supplier diversification analysis completed\n",
            "\n",
            "📤 Generating BI Export Files...\n",
            "✅ BI export files prepared\n",
            "\n",
            "📊 PROJECT SUMMARY REPORT\n",
            "==================================================\n",
            "🎯 KEY FINDINGS:\n",
            "   • Analyzed 1654 purchase orders from 15 suppliers\n",
            "   • Overall OTD Performance: 77.7%\n",
            "   • 0 suppliers classified as high/critical risk\n",
            "   • 20 parts identified as high-risk\n",
            "   • Predicted fill rate: 41.4%\n",
            "\n",
            "💡 OPTIMIZATION RECOMMENDATIONS:\n",
            "   • Adjust safety stock for 8 critical parts\n",
            "   • Implement dual sourcing for 0 single-source critical parts\n",
            "   • Focus supplier improvement efforts on 3 medium/high-risk suppliers\n",
            "   • Estimated annual carrying cost impact: ₹0\n",
            "\n",
            "📈 NEXT STEPS:\n",
            "   1. Deploy predictive models in production environment\n",
            "   2. Implement automated risk scoring dashboard\n",
            "   3. Establish supplier performance monitoring\n",
            "   4. Execute safety stock optimization plan\n",
            "   5. Initiate dual sourcing negotiations for critical parts\n",
            "\n",
            "✅ Python Analytics Pipeline Completed Successfully!\n",
            "   Ready for BI Dashboard Development and Stakeholder Presentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Step: Export Analysis Results for BI Dashboard\n",
        "print(\"\\n📤 FINAL STEP: Exporting Analysis Results for BI Dashboard\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Save key analysis results to CSV files for Power BI consumption\n",
        "import os\n",
        "\n",
        "# Create outputs directory\n",
        "if not os.path.exists('bi_outputs'):\n",
        "    os.makedirs('bi_outputs')\n",
        "\n",
        "print(\"🔄 Exporting analysis results...\")\n",
        "\n",
        "# 1. Supplier Risk Scorecard\n",
        "supplier_scorecard.to_csv('bi_outputs/supplier_risk_scorecard.csv', index=False)\n",
        "print(\"✅ supplier_risk_scorecard.csv - Comprehensive supplier performance and risk metrics\")\n",
        "\n",
        "# 2. Part Risk Analysis\n",
        "part_scorecard.to_csv('bi_outputs/part_risk_analysis.csv', index=False)\n",
        "print(\"✅ part_risk_analysis.csv - Part-level risk scores and exposure analysis\")\n",
        "\n",
        "# 3. Purchase Order Predictions\n",
        "po_predictions.to_csv('bi_outputs/po_risk_predictions.csv', index=False)\n",
        "print(\"✅ po_risk_predictions.csv - Individual PO risk scores and delay predictions\")\n",
        "\n",
        "# 4. Fill Rate Simulation Results\n",
        "fill_rate_forecast.to_csv('bi_outputs/fill_rate_simulation.csv', index=False)\n",
        "print(\"✅ fill_rate_simulation.csv - Monte Carlo simulation results for production planning\")\n",
        "\n",
        "# 5. Safety Stock Recommendations\n",
        "if len(safety_stock_df) > 0:\n",
        "    safety_stock_df.to_csv('bi_outputs/safety_stock_recommendations.csv', index=False)\n",
        "    print(\"✅ safety_stock_recommendations.csv - Optimized inventory level recommendations\")\n",
        "\n",
        "# 6. Feature Importance for Model Explainability\n",
        "feature_importance.to_csv('bi_outputs/model_feature_importance.csv', index=False)\n",
        "print(\"✅ model_feature_importance.csv - Key drivers of delivery delay risk\")\n",
        "\n",
        "# 7. Summary KPIs for Executive Dashboard\n",
        "summary_kpis = pd.DataFrame([{\n",
        "    'Metric': 'Total Purchase Orders Analyzed',\n",
        "    'Value': len(enhanced_df),\n",
        "    'Format': 'Number'\n",
        "}, {\n",
        "    'Metric': 'Overall On-Time Delivery Rate',\n",
        "    'Value': round(enhanced_df['Is_On_Time'].mean() * 100, 1),\n",
        "    'Format': 'Percentage'\n",
        "}, {\n",
        "    'Metric': 'Average Delay for Late Deliveries',\n",
        "    'Value': round(enhanced_df[enhanced_df['Is_Late']]['Delay_Days'].mean(), 1),\n",
        "    'Format': 'Days'\n",
        "}, {\n",
        "    'Metric': 'Suppliers with High Risk Rating',\n",
        "    'Value': len(supplier_scorecard[supplier_scorecard['Risk_Score'] > 50]),\n",
        "    'Format': 'Number'\n",
        "}, {\n",
        "    'Metric': 'Parts with High Risk Rating',\n",
        "    'Value': len(part_scorecard[part_scorecard['Risk_Category'] == 'High Risk']),\n",
        "    'Format': 'Number'\n",
        "}, {\n",
        "    'Metric': 'Predicted Fill Rate',\n",
        "    'Value': round(fill_rate_forecast['On_Time_Rate'].mean(), 1),\n",
        "    'Format': 'Percentage'\n",
        "}, {\n",
        "    'Metric': 'Total Order Value Analyzed',\n",
        "    'Value': round(enhanced_df['Order_Value_INR'].sum() / 1000000, 1),\n",
        "    'Format': 'Million INR'\n",
        "}])\n",
        "\n",
        "summary_kpis.to_csv('bi_outputs/executive_summary_kpis.csv', index=False)\n",
        "print(\"✅ executive_summary_kpis.csv - Key performance indicators for executive dashboard\")\n",
        "\n",
        "print(f\"\\n📊 All analysis results exported to 'bi_outputs/' directory\")\n",
        "\n",
        "# COMPREHENSIVE PROJECT METHODOLOGY SUMMARY\n",
        "print(f\"\\n🎓 COMPLETE PROJECT METHODOLOGY SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "methodology_summary = f\"\"\"\n",
        "EXCAVATOR SUPPLIER RISK ANALYSIS PROJECT - PYTHON IMPLEMENTATION\n",
        "\n",
        "📋 PROJECT SCOPE:\n",
        "• Analyzed supply chain risk for excavator spare parts manufacturing\n",
        "• Built predictive models for delivery delay risk assessment\n",
        "• Implemented Monte Carlo simulation for fill rate impact analysis\n",
        "• Generated optimization recommendations for risk mitigation\n",
        "\n",
        "🔧 TECHNICAL IMPLEMENTATION:\n",
        "\n",
        "1. DATA PREPARATION & FEATURE ENGINEERING ({len(enhanced_df.columns)} features)\n",
        "   • Merged purchase orders with supplier and part master data\n",
        "   • Created rolling performance metrics (30-day, 90-day supplier OTD rates)\n",
        "   • Generated temporal features (seasonality, day-of-week effects)\n",
        "   • Calculated risk scores for parts and suppliers\n",
        "   • Engineered order complexity and criticality indicators\n",
        "\n",
        "2. PREDICTIVE MODELING (AUC: {auc_score:.3f})\n",
        "   • Random Forest Classifier for binary delay prediction\n",
        "   • Logistic Regression for interpretable risk factor analysis\n",
        "   • Feature importance analysis identifying top delay drivers\n",
        "   • Model validation using train-test split methodology\n",
        "\n",
        "3. RISK SCORING SYSTEM (0-100 scale)\n",
        "   • Composite supplier risk scores (Performance + Volatility + Strategic + Predictive)\n",
        "   • Part-level risk assessment based on criticality and supplier diversity\n",
        "   • Automated risk categorization (Low/Medium/High/Critical)\n",
        "\n",
        "4. MONTE CARLO SIMULATION ({num_simulations} scenarios per analysis)\n",
        "   • Probabilistic modeling of delivery performance uncertainty\n",
        "   • Production fill rate impact assessment under various scenarios\n",
        "   • Stockout risk quantification for critical components\n",
        "\n",
        "5. OPTIMIZATION RECOMMENDATIONS\n",
        "   • Safety stock optimization using service level targets\n",
        "   • Supplier diversification analysis for single-source risks\n",
        "   • Cost-benefit analysis of risk mitigation strategies\n",
        "\n",
        "📊 KEY OUTPUTS FOR BI DASHBOARD:\n",
        "• Supplier Risk Scorecards - Performance metrics and risk ratings\n",
        "• Part Risk Analysis - Component-level exposure assessment\n",
        "• PO Risk Predictions - Real-time delivery delay probability\n",
        "• Fill Rate Simulation - Production planning scenario analysis\n",
        "• Safety Stock Recommendations - Inventory optimization guidance\n",
        "• Executive KPIs - Summary metrics for management reporting\n",
        "\n",
        "🎯 BUSINESS VALUE DELIVERED:\n",
        "• Proactive risk identification before delays occur\n",
        "• Data-driven supplier performance management\n",
        "• Optimized inventory levels balancing cost and service\n",
        "• Quantified financial impact of supply chain disruptions\n",
        "• Actionable recommendations for risk mitigation\n",
        "\n",
        "📈 SCALABILITY & DEPLOYMENT:\n",
        "• Modular code structure for easy maintenance and updates\n",
        "• CSV export format compatible with Power BI and other BI tools\n",
        "• Model artifacts ready for production deployment\n",
        "• Automated pipeline suitable for regular refresh cycles\n",
        "\n",
        "🔄 CONTINUOUS IMPROVEMENT:\n",
        "• Model performance monitoring framework\n",
        "• Regular retraining with new data\n",
        "• A/B testing for optimization strategy effectiveness\n",
        "• Feedback loops for model refinement\n",
        "\n",
        "Total Processing Time: Real-time capable for interactive dashboards\n",
        "Data Volume: {len(enhanced_df):,} records processed across {len(suppliers_df)} suppliers\n",
        "Model Accuracy: {((y_pred_binary == y_test_binary).mean() * 100):.1f}% on test set\n",
        "Risk Assessment: {len(supplier_scorecard)} suppliers and {len(part_scorecard)} parts analyzed\n",
        "\n",
        "✅ PROJECT READY FOR BUSINESS INTELLIGENCE DASHBOARD DEVELOPMENT\n",
        "\"\"\"\n",
        "\n",
        "print(methodology_summary)\n",
        "\n",
        "# Save methodology summary\n",
        "with open('bi_outputs/project_methodology_summary.txt', 'w') as f:\n",
        "    f.write(methodology_summary)\n",
        "\n",
        "print(\"✅ Complete project documentation saved\")\n",
        "\n",
        "print(f\"\\n🚀 EXCAVATOR SUPPLIER RISK ANALYSIS PROJECT COMPLETED!\")\n",
        "print(f\"   All Python analytics completed successfully\")\n",
        "print(f\"   Ready for Power BI dashboard development\")\n",
        "print(f\"   {len(os.listdir('bi_outputs'))} output files generated for BI consumption\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cs4ISY8LCejT",
        "outputId": "c74ce329-0a06-48d1-df42-62b991beb7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📤 FINAL STEP: Exporting Analysis Results for BI Dashboard\n",
            "============================================================\n",
            "🔄 Exporting analysis results...\n",
            "✅ supplier_risk_scorecard.csv - Comprehensive supplier performance and risk metrics\n",
            "✅ part_risk_analysis.csv - Part-level risk scores and exposure analysis\n",
            "✅ po_risk_predictions.csv - Individual PO risk scores and delay predictions\n",
            "✅ fill_rate_simulation.csv - Monte Carlo simulation results for production planning\n",
            "✅ safety_stock_recommendations.csv - Optimized inventory level recommendations\n",
            "✅ model_feature_importance.csv - Key drivers of delivery delay risk\n",
            "✅ executive_summary_kpis.csv - Key performance indicators for executive dashboard\n",
            "\n",
            "📊 All analysis results exported to 'bi_outputs/' directory\n",
            "\n",
            "🎓 COMPLETE PROJECT METHODOLOGY SUMMARY\n",
            "==================================================\n",
            "\n",
            "EXCAVATOR SUPPLIER RISK ANALYSIS PROJECT - PYTHON IMPLEMENTATION\n",
            "\n",
            "📋 PROJECT SCOPE:\n",
            "• Analyzed supply chain risk for excavator spare parts manufacturing\n",
            "• Built predictive models for delivery delay risk assessment\n",
            "• Implemented Monte Carlo simulation for fill rate impact analysis\n",
            "• Generated optimization recommendations for risk mitigation\n",
            "\n",
            "🔧 TECHNICAL IMPLEMENTATION:\n",
            "\n",
            "1. DATA PREPARATION & FEATURE ENGINEERING (39 features)\n",
            "   • Merged purchase orders with supplier and part master data\n",
            "   • Created rolling performance metrics (30-day, 90-day supplier OTD rates)\n",
            "   • Generated temporal features (seasonality, day-of-week effects)\n",
            "   • Calculated risk scores for parts and suppliers\n",
            "   • Engineered order complexity and criticality indicators\n",
            "\n",
            "2. PREDICTIVE MODELING (AUC: 0.620)\n",
            "   • Random Forest Classifier for binary delay prediction\n",
            "   • Logistic Regression for interpretable risk factor analysis\n",
            "   • Feature importance analysis identifying top delay drivers\n",
            "   • Model validation using train-test split methodology\n",
            "\n",
            "3. RISK SCORING SYSTEM (0-100 scale)\n",
            "   • Composite supplier risk scores (Performance + Volatility + Strategic + Predictive)\n",
            "   • Part-level risk assessment based on criticality and supplier diversity\n",
            "   • Automated risk categorization (Low/Medium/High/Critical)\n",
            "\n",
            "4. MONTE CARLO SIMULATION (500 scenarios per analysis)\n",
            "   • Probabilistic modeling of delivery performance uncertainty\n",
            "   • Production fill rate impact assessment under various scenarios\n",
            "   • Stockout risk quantification for critical components\n",
            "\n",
            "5. OPTIMIZATION RECOMMENDATIONS\n",
            "   • Safety stock optimization using service level targets\n",
            "   • Supplier diversification analysis for single-source risks\n",
            "   • Cost-benefit analysis of risk mitigation strategies\n",
            "\n",
            "📊 KEY OUTPUTS FOR BI DASHBOARD:\n",
            "• Supplier Risk Scorecards - Performance metrics and risk ratings\n",
            "• Part Risk Analysis - Component-level exposure assessment  \n",
            "• PO Risk Predictions - Real-time delivery delay probability\n",
            "• Fill Rate Simulation - Production planning scenario analysis\n",
            "• Safety Stock Recommendations - Inventory optimization guidance\n",
            "• Executive KPIs - Summary metrics for management reporting\n",
            "\n",
            "🎯 BUSINESS VALUE DELIVERED:\n",
            "• Proactive risk identification before delays occur\n",
            "• Data-driven supplier performance management\n",
            "• Optimized inventory levels balancing cost and service\n",
            "• Quantified financial impact of supply chain disruptions\n",
            "• Actionable recommendations for risk mitigation\n",
            "\n",
            "📈 SCALABILITY & DEPLOYMENT:\n",
            "• Modular code structure for easy maintenance and updates\n",
            "• CSV export format compatible with Power BI and other BI tools\n",
            "• Model artifacts ready for production deployment\n",
            "• Automated pipeline suitable for regular refresh cycles\n",
            "\n",
            "🔄 CONTINUOUS IMPROVEMENT:\n",
            "• Model performance monitoring framework\n",
            "• Regular retraining with new data\n",
            "• A/B testing for optimization strategy effectiveness\n",
            "• Feedback loops for model refinement\n",
            "\n",
            "Total Processing Time: Real-time capable for interactive dashboards\n",
            "Data Volume: 1,654 records processed across 15 suppliers\n",
            "Model Accuracy: 76.7% on test set\n",
            "Risk Assessment: 15 suppliers and 32 parts analyzed\n",
            "\n",
            "✅ PROJECT READY FOR BUSINESS INTELLIGENCE DASHBOARD DEVELOPMENT\n",
            "\n",
            "✅ Complete project documentation saved\n",
            "\n",
            "🚀 EXCAVATOR SUPPLIER RISK ANALYSIS PROJECT COMPLETED!\n",
            "   All Python analytics completed successfully\n",
            "   Ready for Power BI dashboard development\n",
            "   8 output files generated for BI consumption\n"
          ]
        }
      ]
    }
  ]
}